import numpy as np
import pandas as pd

# the cleaned datasets are being loaded for augmentation
dataframe_cleaned = pd.read_csv('../assets/cleaned_fraud_train.csv')
dataframe_test_cleaned = pd.read_csv('../assets/cleaned_fraud_test.csv')


# Function to generate one synthetic row using the distributions
def generate_synthetic_row(distributions):
    row = {}
    # the identifier refers to the column or the key in the key-value pair of the object
    # the dist is the distribution of each element in a column
    for identifier, dist in distributions.items():
        # the p refers toe probability of a certain element appearing in a random selection
        # this ensures that values selected at random conforms with a realistic pattern
        row[identifier] = np.random.choice(dist.index, p=dist.values)
    return row


def augment_data(df_cleaned):
    # the plan is to generate a data times 10 of the original data
    # the original data already accounts for 1 out of the 10 leaving us with 9
    # the length of the data is therefore multiplied by 9 to get the length of the synthetic data
    rows_to_generate = len(df_cleaned) * 4

    # an object to capture the distributions of elements in a particular column is instantiated here
    value_distributions = {}
    # this loops through the columns in the dataset
    for col in df_cleaned.columns:
        # the frequency of each value in the current column of the iteration is fetched and normalized
        value_counts = df_cleaned[col].value_counts(normalize=True)
        # this creates and element with the name of the column 'col' as key and assigns the counts as value
        value_distributions[col] = value_counts

    # the synthetic rows are generated by looping through the range of rows to be generated initially calculated
    # the distribution object is fed into the previously defined functions of 'generate_synthetic_row' to populate
    # values at random
    synthetic_rows = [generate_synthetic_row(value_distributions) for _ in range(rows_to_generate)]

    # the synthetic row is converted into a pandas DataFrame
    df_synthetic = pd.DataFrame(synthetic_rows)

    # to ensure that it is up to times 10 of the initial dataframe, the initial dataframe is combined with
    # the synthetic dataframe which is a length of multiple of 9
    df_augmented = pd.concat([df_cleaned, df_synthetic], ignore_index=True)
    # in the augmentation process, there are bound to be repetitions. Dropping duplicates ensures every entry
    # is unique
    # The inplace argument helps avoid assigning the resulting dataframe to the 'df_augmented' variable
    df_augmented.drop_duplicates(inplace=True)
    return df_augmented


# the augmentation is applied on both training and test data
dataframe_cleaned = augment_data(dataframe_cleaned)
dataframe_test_cleaned = augment_data(dataframe_test_cleaned)

dataframe_cleaned.to_csv('../assets/augmented_fraud_train.csv', index=False)
dataframe_test_cleaned.to_csv('../assets/augmented_fraud_test.csv', index=False)
