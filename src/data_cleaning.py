import json
import pandas as pd
from haversine import haversine
from datetime import date
from pathlib import Path
from src.compile_file_path import get_file_path

# loads the training dataset
dataframe = pd.read_csv(get_file_path('assets/fraudTrain.csv'))
# loads the test dataset
dataframe_test = pd.read_csv(get_file_path('assets/fraudTest.csv'))
# a list of columns that will no longer be needed after the necessary information has been extracted including
# the first column which is unnamed
columns_to_remove = [dataframe.columns[0], 'cc_num', 'trans_num', 'unix_time', 'dob', 'trans_date_trans_time', 'lat',
                     'long', 'merch_lat', 'merch_long', 'job', 'age', 'amt', 'trans_distance', 'street', 'state', 'zip',
                     'city_pop', 'trans_hour', 'trans_month', 'first', 'last', 'city', 'merchant']

# jobs are categorised into sectors and the sectors are loaded from a json file
job_sectors = json.load(Path(get_file_path('misc/job_sector.json')).open())
age_groups = json.load(Path(get_file_path('misc/age_group.json')).open())


# this extracts the month and hour of transaction from trans_date_trans_time column
def extract_date(data):
    split_data = str(data).split(" ")
    trans_date = split_data[0]
    time = split_data[1]
    trans_date = trans_date.split("-")[1]
    time = time.split(":")[0]
    return pd.Series([int(trans_date), int(time)])


# sets time of day based on corresponding 24 hour time
def get_time_of_day(hour):
    if 0 <= hour < 6:
        return 'Late Night'
    elif 6 <= hour < 12:
        return 'Morning'
    elif 12 <= hour < 17:
        return 'Afternoon'
    elif 17 <= hour < 21:
        return 'Evening'
    else:
        return 'Night'


# sets season based on corresponding month number and the seasons of the northern hemisphere since
# the location in this dataset is the US
def get_season(month):
    if month in [12, 1, 2]:
        return 'Winter'
    elif month in [3, 4, 5]:
        return 'Spring'
    elif month in [6, 7, 8]:
        return 'Summer'
    else:  # 9, 10, 11
        return 'Autumn'


# this uses the haversine formula to get the distance between the card user and the merchant
# the card was being used at
def calculate_distance(data):
    user_coordinates = (data["lat"], data["long"])
    merch_coordinates = (data["merch_lat"], data["merch_long"])
    distance = haversine(user_coordinates, merch_coordinates, unit='mi')
    return distance


# this extracts the age from the date of birth of the users
def extract_age(data):
    dob = [int(d) for d in str(data).split("-")]
    difference = date.today() - date(dob[0], dob[1], dob[2])
    return difference.days // 365


# divide distances into 4 groups based on percentile distribution
# Only 3 groups are highlighted here with anything more than or equal to the max highlighted as the farthest by default
def prepare_distance_grouping(data_description):
    _, _, _, _, quarter, half, three_quarter, full = data_description
    groupings = {"Nearest": [0, quarter], "Near": [quarter, three_quarter], "Far": [three_quarter, full + 1]}
    return groupings


# set trans_distance into distance groups
def group_distance(data, groupings):
    try:
        selected_group = [k for k, v in groupings.items() if v[0] <= data < v[1]][0]
    except:
        selected_group = "Far"
    return selected_group


# divide city population into 4 groups based on percentile distribution
# Only 3 groups are highlighted here with anything more than or equal to the max
# highlighted as the most populous by default
def prepare_population_grouping(data_description):
    _, _, _, _, quarter, half, three_quarter, full = data_description
    groupings = {"Few": [0, quarter], "Average": [quarter, three_quarter], "Populous": [three_quarter, full + 1]}
    return groupings


# set city_pop into population groups
def group_population(data, groupings):
    try:
        selected_group = [k for k, v in groupings.items() if v[0] <= data < v[1]][0]
    except:
        selected_group = "Populous"
    return selected_group


# this applies the job sector based on the jobs highlighted in the job column
# it proceeds to apply 'Other' to jobs without a specified sector
def set_job_sector(data):
    try:
        selected_sector = [k for k, v in job_sectors.items() if data in v][0]
    except:
        selected_sector = "Other"
    return selected_sector


# set ages into age groups
def group_age(data):
    try:
        selected_group = [k for k, v in age_groups.items() if v[0] <= data <= v[1]][0]
    except:
        selected_group = "Senior Adult"
    return selected_group


# group amounts based on unit, tens, hundreds and beyond
def group_amt(data):
    amount_length = len(str(int(data)))
    if amount_length > 3:
        amount_length = 3
    return amount_length


# this carries out the cleaning and application of cleaning functions to the dataframes passed through
def clean_dataframe(dataframe_copy):
    # an 'age' column is generated by applying age extracting to the 'dob' column
    dataframe_copy["age"] = dataframe_copy["dob"].apply(extract_age)
    # apply age group categorisation to the age column
    dataframe_copy["age_group"] = dataframe_copy["age"].apply(group_age)
    # apply amount categorisation to the amt column
    dataframe_copy["amt_group"] = dataframe_copy["amt"].apply(group_amt)
    # a 'job_sector' column is generated by setting the job sectors on the 'job' column
    dataframe_copy["job_sector"] = dataframe_copy["job"].apply(set_job_sector)
    # the 'trans_month' and 'trans_hour' columns are formed from the date-time column simultaneously
    dataframe_copy[["trans_month", "trans_hour"]] = dataframe_copy["trans_date_trans_time"].apply(extract_date)
    # groups the hour into category of time of day e.g. Night, Day, Midnight, etc.
    dataframe_copy['time_of_day'] = dataframe_copy['trans_hour'].apply(get_time_of_day)
    # groups the month into season
    dataframe_copy['season'] = dataframe_copy['trans_month'].apply(get_season)
    # the 'trans_distance' column formed by applying the 'calculate_distance' function on the first axis
    # of the dataframe
    dataframe_copy["trans_distance"] = dataframe_copy.apply(calculate_distance, axis=1)
    groupings = prepare_distance_grouping(dataframe_copy['trans_distance'].describe())
    dataframe_copy["trans_distance_group"] = dataframe_copy['trans_distance'].apply(
        lambda x: group_distance(x, groupings))
    population_groupings = prepare_population_grouping(dataframe_copy['city_pop'].describe())
    dataframe_copy["city_pop_group"] = dataframe_copy['city_pop'].apply(
        lambda x: group_population(x, population_groupings))
    # the predefined columns to be removed are dropped on the first axis
    try:
        dataframe_copy = dataframe_copy.drop(columns_to_remove, axis=1)
    except KeyError:
        columns_to_remove.pop(0)
        dataframe_copy = dataframe_copy.drop(columns_to_remove, axis=1)
    return dataframe_copy


# the cleaned dataframes for both training and testing
# dataframe = clean_dataframe(dataframe)
# dataframe_test = clean_dataframe(dataframe_test)

# the cleaned dataset is saved to new files with 'index' set to false
# to avoid an unnamed index column in the resulting file
# dataframe.to_csv('../assets/cleaned_fraud_train.csv', index=False)
# dataframe_test.to_csv('../assets/cleaned_fraud_test.csv', index=False)
